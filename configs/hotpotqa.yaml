model:
  name: "openrouter/meta-llama/llama-3.3-70b-instruct"
  api_base: "https://openrouter.ai/api/v1"
  temperature: 0.0
  max_tokens: 2048

dataset:
  adapter_class: "prompt_ops.datasets.hotpotqa.HotpotQAAdapter"
  path: "/Users/justinai/Documents/Code/prompt-ops/use-cases/hotpotqa/hotpotqa_sample.json"
  train_size: 0.005
  validation_size: 0.005
  test_size: 0.008
  adapter_params:
    passages_per_hop: 3
    max_hops: 2
    retriever_url: null # Set to a valid ColBERT URL if available
    # Explicitly define input and output field mappings
    input_field: "question"  # Primary input field is the question
    context_field: "context"  # Field containing context passages
    supporting_facts_field: "supporting_facts"  # Field containing supporting facts
    golden_output_field: "answer"  # Field to use as ground truth/reference output

prompt:
  text: |
    You are an expert at answering complex questions that require multi-hop reasoning.
  inputs: ["question", "context"]
  outputs: ["answer"]

metric:
  class: "prompt_ops.datasets.hotpotqa.HotpotQAMetric"
  output_field: "answer"
  passage_weight: 0.5

strategy:
  class: "prompt_ops.core.prompt_strategies.BasicOptimizationStrategy"
  num_threads: 1
  max_examples: 3
  max_bootstrapped_demos: 0
  max_labeled_demos: 0
  num_candidates: 1
  auto: "basic"
  minibatch: false
